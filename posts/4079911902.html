<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>第一个成熟的卷积神经网络——字符识别 | Yangyy's Life</title><meta name="keywords" content="卷积神经网络,Python,深度学习,车牌识别项目"><meta name="author" content="yangyy"><meta name="copyright" content="yangyy"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="总算是开始了自己的第一篇技术博客。">
<meta property="og:type" content="article">
<meta property="og:title" content="第一个成熟的卷积神经网络——字符识别">
<meta property="og:url" content="https://yangyy.top/posts/4079911902.html">
<meta property="og:site_name" content="Yangyy&#39;s Life">
<meta property="og:description" content="总算是开始了自己的第一篇技术博客。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.ax1x.com/2022/10/27/xhVEB6.jpg">
<meta property="article:published_time" content="2022-07-15T15:13:38.000Z">
<meta property="article:modified_time" content="2023-01-12T14:03:35.470Z">
<meta property="article:author" content="yangyy">
<meta property="article:tag" content="卷积神经网络">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="车牌识别项目">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.ax1x.com/2022/10/27/xhVEB6.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://yangyy.top/posts/4079911902"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '第一个成熟的卷积神经网络——字符识别',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-01-12 22:03:35'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Yangyy's Life" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/header2.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">59</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fas fa-commenting"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于作者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s1.ax1x.com/2022/10/27/xhVEB6.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yangyy's Life</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fas fa-commenting"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于作者</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">第一个成熟的卷积神经网络——字符识别</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-07-15T15:13:38.000Z" title="发表于 2022-07-15 23:13:38">2022-07-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-01-12T14:03:35.470Z" title="更新于 2023-01-12 22:03:35">2023-01-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>7分钟</span></span><span class="post-meta-separator">|</span><span class="leancloud_visitors" id="/posts/4079911902.html" data-flag-title="第一个成熟的卷积神经网络——字符识别"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span class="leancloud-visitors-count"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/posts/4079911902.html#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/posts/4079911902.html" itemprop="commentCount"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>​		总算是开始了自己的第一篇技术博客。</p>
<p>​		也总算是大概弄懂了一些深度学习、神经网络、卷积神经网络的知识，能靠自己实现识别字符的卷积神经网络了。</p>
<p>​		今天时间所剩不多，可能写不完，写到哪算哪吧。</p>
<p>​		在大二下的《人工智能导论》这门课开始接触深度学习，学得一知半解都算不上，啥都没弄明白，甚至还要做神经网络的实验，本是作为启蒙课的目的也没有达到，反而起到了揠苗助长的效果，让人觉得深度学习、神经网络特别难。就我目前的理解而言，我绝不敢说深度学习、神经网络简单，毕竟现在科技前沿都还没将之完全征服。但是我可以说，理解深度学习、神经网络的基本概念绝对不难。实际上我到目前为止也只是看了吴恩达老师不到半小时的讲解就入门了神经网络，实训课李伟老师一上午左右的讲解也让我掌握了数字图像基本概念和卷积神经网络的思路。不得不抨击一下这门课的设立，我被老师和实验弄迷糊的时间完全可以入门深度学习了，况且还让我很长一段时间对深度学习、神经网络有些畏惧，如今看来，似乎”不过如此“（bushi）。</p>
<p>​		好吧，啰嗦了半天，好像都没时间写技术性的东西了。</p>
<p>​		这次的任务是把老师已经用tensorflow1.x写好的识别字符的卷积神经网络改成用tensorflow2.x实现**（封装的特性）**。关于深度学习和神经网络的知识梳理有空再写吧。</p>
<p>​		先到这里。</p>
<p>​		————————————————————2022/7/15  23：28</p>
<p>​		————————————————————2022/7/17  9：41接着写</p>
<p>​		拖欠了两天都没写完哈哈。不过下一阶段的任务还没开始，也不急。字符识别卷积神经网络搭好了，接下来就是web的搭建了，Python的flask是完全没学过的内容。</p>
<p>​		直接按照搭建网络的顺序逐个说明吧。</p>
<p><strong>一.数据读取</strong></p>
<p>现在很多CV领域的数据读取都是直接读取现成的数据集，但是这里需要从本地文件当中读取，并进行处理，这一部分tf1和tf2没区别，不用改。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span>(<span class="params">dir_path</span>):</span></span><br><span class="line">    data = []</span><br><span class="line">    labels = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> os.listdir(dir_path):</span><br><span class="line">        item_path = os.path.join(dir_path, item)</span><br><span class="line">        <span class="keyword">if</span> os.path.isdir(item_path):</span><br><span class="line">            <span class="keyword">for</span> subitem <span class="keyword">in</span> os.listdir(item_path):</span><br><span class="line">                subitem_path = os.path.join(item_path, subitem)</span><br><span class="line">                gray_image = cv.imread(subitem_path, cv.IMREAD_GRAYSCALE)</span><br><span class="line">                resized_image = cv.resize(gray_image, (IMAGE_WIDTH, IMAGE_HEIGHT))</span><br><span class="line">                data.append(resized_image.ravel())</span><br><span class="line">                labels.append(LABEL_DICT[item])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array(data), np.array(labels)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">data文件夹里面有0~1，A~Z的所有字符，每个字符有一个文件夹存储对应图片，这部分代码的功能就是把每个图片读出来，转换成20*20的大小，label就是文件夹名称</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></tbody></table></figure>
<p>正式进行数据读取的步骤开始有了变化。原本会对训练集和测试集都进行正则化，然后再把标签独热编码，这两步都是自定义的函数。tf2提供相关的API。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取训练集的特征矩阵、标签向量</span></span><br><span class="line">train_data, train_labels = load_data(TRAIN_DIR)</span><br><span class="line"><span class="comment"># 对训练集的标签向量执行独热编码,tf2提供API</span></span><br><span class="line">train_labels = tf.one_hot(train_labels, <span class="number">34</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取训练集的总样本数</span></span><br><span class="line">train_samples_count = <span class="built_in">len</span>(train_data)</span><br><span class="line">train_indicies = np.arange(train_samples_count)</span><br><span class="line"><span class="comment"># 获得打乱的索引序列</span></span><br><span class="line">np.random.shuffle(train_indicies)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取测试集的特征矩阵、标签向量</span></span><br><span class="line">test_data, test_labels = load_data(TEST_DIR)</span><br><span class="line"><span class="comment"># 对测试集的标签向量执行独热编码</span></span><br><span class="line">test_labels = tf.one_hot(test_labels, <span class="number">34</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入tf2搭建的网络之后还要reshape，变成[N, width, height, 1(灰度图)]的形式</span></span><br><span class="line">train_data = tf.reshape(train_data, (train_data.shape[<span class="number">0</span>], IMAGE_WIDTH, IMAGE_HEIGHT, <span class="number">1</span>))</span><br><span class="line">test_data = tf.reshape(test_data, (test_data.shape[<span class="number">0</span>], IMAGE_WIDTH, IMAGE_HEIGHT, <span class="number">1</span>))</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">可能会问，原先的正则化哪去了，答案是：直接在神经网络入口加一层正则化层就行</span></span><br><span class="line"><span class="string">这样不用分别处理训练集和测试集，它们进入网络就会正则化了</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></tbody></table></figure>
<p><strong>二.搭建网络（封装的特性）</strong></p>
<p>tf2搭建网络最明显的特点就是<strong>封装的特性</strong>，直接在一个对象当中设置好每一层的参数就可以，不需要手动实现底层代码，有了非常明显的改进。</p>
<p>直接上代码。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">network = tf.keras.models.Sequential([</span><br><span class="line">    <span class="comment"># 正式操作之前先进行正则化，专门的正则化层</span></span><br><span class="line">    tf.keras.layers.BatchNormalization(),</span><br><span class="line">    <span class="comment"># 第一层卷积层，32个卷积核，大小5*5，自动初始化，relu激活，输入形状固定</span></span><br><span class="line">    tf.keras.layers.Conv2D(filters=<span class="number">32</span>, kernel_size=<span class="number">5</span>, activation=<span class="string">'relu'</span>, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, <span class="number">1</span>), padding=<span class="string">'same'</span>),</span><br><span class="line">    <span class="comment"># 第一层池化层</span></span><br><span class="line">    tf.keras.layers.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>),  <span class="comment"># 20=&gt;10，步长应该取2</span></span><br><span class="line">    <span class="comment"># 第二层卷积层</span></span><br><span class="line">    tf.keras.layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">5</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10</span>, <span class="number">10</span>, <span class="number">32</span>), padding=<span class="string">'same'</span>),</span><br><span class="line">    <span class="comment"># 第二层池化层</span></span><br><span class="line">    tf.keras.layers.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>),  <span class="comment"># 10=&gt;5</span></span><br><span class="line">    <span class="comment"># 把二维矩阵展平成向量</span></span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    <span class="comment"># 全连接层</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1024</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    <span class="comment"># 全连接之后会导致参数爆炸，需要dropout一些数据</span></span><br><span class="line">    tf.keras.layers.Dropout(<span class="number">0.3</span>),</span><br><span class="line">    <span class="comment"># 仿射函数</span></span><br><span class="line">    tf.keras.layers.Dense(CLASSIFICATION_COUNT, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br></pre></td></tr></tbody></table></figure>
<p>这只是前向传播的代码，交叉熵损失函数和反向传播算法如下。</p>
<figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">network.compile(<span class="attr">optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),</span>	<span class="comment"># 反向传播算法&amp;学习率设置</span></span><br><span class="line">    <span class="attr">loss=tf.keras.losses.BinaryCrossentropy(),</span>	<span class="comment"># 交叉熵损失函数</span></span><br><span class="line">    <span class="attr">metrics=['accuracy'])</span></span><br></pre></td></tr></tbody></table></figure>
<p><strong>三.训练模型、评估准确率、保存模型</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">network.fit(train_data, train_labels, batch_size=<span class="number">50</span>, epochs=<span class="number">30</span>, validation_split=<span class="number">0.02</span>)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">直接指定batch_size和epochs即可，很方便</span></span><br><span class="line"><span class="string">validation_split这个参数就是每次训练时，把训练集中一定比例的数据不参与训练，用来测算正确率等参数，测出来也不改变参数</span></span><br><span class="line"><span class="string">最开始validation_split=0.1的时候，训练当中算出来的正确率很高，98/99%甚至100%。但是测试集效果不好，正确率89%左右。我估计是因为直接削减了10%的数据，泛化能力不强。</span></span><br><span class="line"><span class="string">但是如果设置validation_split=0.0，训练和测试效果很好，98~99%，但是实际检测效果反而不如前者，说明可能过拟合了</span></span><br><span class="line"><span class="string">所以设置validation_split=0.02，这样中庸的策略既保证了正确率，泛化能力又不错</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估准确率</span></span><br><span class="line">test_loss, test_acc = network.evaluate(test_data, test_labels)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'\n测试准确率：'</span>, test_acc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">network.save_weights(MODEL_PATH)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">保存模型可以直接保存模型。也可以保存模型的权重（参数），预测的时候，构造一个同架构的网络，直接加载参数即可。</span></span><br><span class="line"><span class="string">前者比较友好，很简单，但是队友用了后者就用后者吧，我觉得后者会更快，因为直接加载参数显然比直接加载模型要更简单</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></tbody></table></figure>
<p><strong>四.实战预测</strong></p>
<p>1.自定义一个加载图片的函数。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_image</span>(<span class="params">image_path, width, height</span>):</span></span><br><span class="line">    gray_image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)</span><br><span class="line">    resized_image = cv.resize(gray_image, (width, height))</span><br><span class="line">    data = []</span><br><span class="line">    data.append(resized_image.ravel())</span><br><span class="line">    <span class="keyword">return</span> np.array(data)</span><br></pre></td></tr></tbody></table></figure>
<p>2.搭建一个网络，并加载权重|参数，这主要是由之前保存只是保存了参数决定的，如果保存的是模型，就直接加载好了。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载训练好的模型</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    <span class="comment"># 网络的具体架构不重复，和前文完全一致</span></span><br><span class="line">])</span><br><span class="line"><span class="comment"># 加载参数</span></span><br><span class="line">model.load_weights(<span class="string">"model/my_cnn_enu"</span>)</span><br><span class="line"><span class="comment"># 这样，model就是之前训练好的模型了</span></span><br></pre></td></tr></tbody></table></figure>
<p>3.读取图片，reshape成可以进入网络的样子</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">digit_image_path = <span class="string">"images/english.jpg"</span></span><br><span class="line">digit_image = load_image(digit_image_path, IMAGE_WIDTH, IMAGE_HEIGHT)</span><br><span class="line">english_image = tf.reshape(digit_image, [-<span class="number">1</span>, IMAGE_WIDTH, IMAGE_HEIGHT, <span class="number">1</span>])</span><br></pre></td></tr></tbody></table></figure>
<p>4.预测</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">results = model.predict(english_image)</span><br><span class="line"><span class="comment"># 选概率最大的</span></span><br><span class="line">num = np.argmax(results[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 通过索引转成对应的字符</span></span><br><span class="line">new_dict = {v : k <span class="keyword">for</span> k, v <span class="keyword">in</span> LABEL_DICT.items()}<span class="comment">#反转字典</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"预测结果是："</span>, new_dict[num])</span><br><span class="line"><span class="comment"># 预测结束</span></span><br></pre></td></tr></tbody></table></figure>
<p><em><strong>以上就是全部的内容了，是不是挺简单的呢，反正我觉得挺简单的，哈哈。</strong></em></p>
<p>让大家看看效果叭。</p>
<p><img src="/posts/4079911902/image1.png" alt="image1"></p>
<p><img src="/posts/4079911902/image2.png" alt="image2"></p>
<p><img src="/posts/4079911902/image3.png" alt="image3"></p>
<p><img src="/posts/4079911902/image4.png" alt="image4"></p>
<p><img src="/posts/4079911902/image5.png" alt="image5"></p>
<p><img src="/posts/4079911902/image6.png" alt="image6"></p>
<p>最后一张预测错惹，没办法，这个A真的很像4。</p>
<p>第一篇技术博客正式完结，实际用时也不久，挺好的。</p>
<p>谢谢观看~</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://yangyy.top">yangyy</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://yangyy.top/posts/4079911902.html">https://yangyy.top/posts/4079911902.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://yangyy.top" target="_blank">Yangyy's Life</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">卷积神经网络</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB%E9%A1%B9%E7%9B%AE/">车牌识别项目</a></div><div class="post_share"><div class="social-share" data-image="https://s1.ax1x.com/2022/10/27/xhVEB6.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/282847613.html"><img class="prev-cover" src="https://s1.ax1x.com/2022/10/27/xhVEB6.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">2022/7/15 日记</div></div></a></div><div class="next-post pull-right"><a href="/posts/2991647163.html"><img class="next-cover" src="https://s1.ax1x.com/2022/10/27/xhVEB6.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">欢迎来到我的博客</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/238374888.html" title="车牌识别项目Web端的搭建"><img class="cover" src="https://s1.ax1x.com/2022/10/27/xhVEB6.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-18</div><div class="title">车牌识别项目Web端的搭建</div></div></a></div><div><a href="/posts/124289153.html" title="《微软公司的时间序列异常检测服务》个人笔记"><img class="cover" src="https://s1.ax1x.com/2022/10/27/xhVEB6.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-12</div><div class="title">《微软公司的时间序列异常检测服务》个人笔记</div></div></a></div><div><a href="/posts/1394742614.html" title="异常检测挑战赛数据绘制"><img class="cover" src="https://s1.ax1x.com/2022/10/27/xhVEB6.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-01</div><div class="title">异常检测挑战赛数据绘制</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/header2.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">yangyy</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">59</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/wending0417"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/4183696190.html" title="二刷TSCP2论文">二刷TSCP2论文</a><time datetime="2023-01-27T03:13:13.000Z" title="发表于 2023-01-27 11:13:13">2023-01-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/1726264158.html" title="保研准备工作梳理">保研准备工作梳理</a><time datetime="2023-01-25T02:11:39.000Z" title="发表于 2023-01-25 10:11:39">2023-01-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/2118603635.html" title="假期中后期的一些回顾与规划">假期中后期的一些回顾与规划</a><time datetime="2023-01-21T01:46:27.000Z" title="发表于 2023-01-21 09:46:27">2023-01-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/2907034089.html" title="在RecBole当中实现DAGFM模型">在RecBole当中实现DAGFM模型</a><time datetime="2023-01-13T02:46:10.000Z" title="发表于 2023-01-13 10:46:10">2023-01-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/1347074556.html" title="通过论文学习DAGFM模型">通过论文学习DAGFM模型</a><time datetime="2023-01-10T00:56:02.000Z" title="发表于 2023-01-10 08:56:02">2023-01-10</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 <i style="color:#FF6A6A" class="fa fa-heartbeat"></i>yangyy</div><div class="footer_custom_text">那些看似不起波澜的日复一日，会突然在某一天让人看到坚持的意义</div><div id="running-time"></div><script>setInterval(()=>{let create_time=Math.round(new Date(Date.UTC(2022,07,14,11,07,28)).getTime()/1000);let timestamp=Math.round((new Date().getTime()+31*24*3600*1000+8*60*60*1000)/1000);let second=timestamp-create_time;let time=new Array(0,0,0,0,0);if(second>=365*24*3600){time[0]=parseInt(second/(365*24*3600));second%=365*24*3600;}if(second>=24*3600){time[1]=parseInt(second/(24*3600));second%=24*3600;}if(second>=3600){time[2]=parseInt(second/3600);second%=3600;}if(second>=60){time[3]=parseInt(second/60);second%=60;}if(second>0){time[4]=second;}currentTimeHtml='本站已安全运行 '+time[0]+' 年 '+time[1]+' 天 '+time[2]+' 时 '+time[3]+' 分 '+time[4]+' 秒';document.getElementById("running-time").innerHTML=currentTimeHtml;},1000);	</script><img src="https://www.yiqiuwl.com/content/uploadfile/202208/cffa1659599066.png">
<a href="http://beian.miit.gov.cn/"  style="color:#f72b07" target="_blank">闽ICP备2022015544号</a></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'Srx46WYtgI2COUqAi761ccR8-gzGzoHsz',
      appKey: 'bNpdyeUlKIvb6bUb42mYvy0h',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>